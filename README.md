# BERT-base-cased Fine-tuning with Embedding MixUp Data Augmentation

## Описание проекта

Проект направлен на демонстрацию процесса файнтюнинга модели [BERT-base-cased](https://huggingface.co/bert-base-cased) на задаче классификации отзывов из датасета [Rotten Tomatoes](https://huggingface.co/datasets/rotten_tomatoes) с использованием метода аугментации данных MixUp на уровне эмбеддингов. 

https://arxiv.org/abs/2303.07864

## Основная идея

Вместо того чтобы обучаться на реальных данных, MixUp создает новые обучающие примеры следующим образом:

1. **Линейное смешивание входов**: Создается новый пример, который является линейной комбинацией двух случайно выбранных примеров из обучающего набора:

   \[
   \tilde{x} = \lambda x_i + (1 - \lambda) x_j
   \]

   где \( x_i \) и \( x_j \) — входные данные, а \(\lambda \in [0, 1]\) — коэффициент смешивания, случайным образом выбранный из бета-распределения.

2. **Линейное смешивание меток**: Метки для нового примера также создаются как линейная комбинация меток исходных примеров:

   \[
   \tilde{y} = \lambda y_i + (1 - \lambda) y_j
   \]

## Преимущества

- **Улучшение обобщающей способности**: Модель учится на большем количестве уникальных примеров, что помогает улучшить её обобщающую способность.
- **Уменьшение переобучения**: Смешивание примеров делает модель менее склонной к переобучению на специфических деталях отдельных примеров.
- **Повышенная устойчивость к шуму**: Модель становится более устойчивой к шуму в данных, так как она обучается на более сглаженных примерах.

## Установка 

Для запуска трэйна понадобится cuda 11.8
Файнтюн на T4 занимает порядка 20 минут

1. 
   git clone https://github.com/revyu/base_bert_cased_Enmix.git
   cd base_bert_cased_Enmix

2. 
    python -m venv venv
    .\venv\Scripts\activate

3. 
    pip install -r requirements.txt





